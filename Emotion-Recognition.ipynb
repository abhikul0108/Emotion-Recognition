{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This notebook contains several feature extraction techniques which are used to extract features from the facial images and then passed to a CNN model to compare their results","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport random\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\nfrom tensorflow.keras import regularizers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loading data","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/input/ckplus')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATADIR = r'/kaggle/input/ckplus/CK+48'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CATEGORIES = os.listdir(DATADIR)\nCATEGORIES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    DATADIR = r'/kaggle/input/ckplus/CK+48'\n    data = []\n    # loading training data\n    for category in CATEGORIES:\n        # create path to image of respective expression\n        path = os.path.join(DATADIR, category)\n        # get the classification  for each expression \n        class_num = CATEGORIES.index(category)\n\n        for img in tqdm(os.listdir(path)):\n            img_array = cv2.imread(os.path.join(path, img), 0)\n            data.append([img_array, class_num])\n            \n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = load_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets Visualize some images ","metadata":{}},{"cell_type":"code","source":"L = 4\nW = 4\nfig, axes = plt.subplots(L, W, figsize = (15,15))\naxes = axes.ravel()\n\nfor i in range(0, L * W):  \n    sample = random.choice(data)\n    axes[i].set_title(\"Expression = \"+str(CATEGORIES[sample[1]]))\n    axes[i].imshow(sample[0], cmap='gray')\n    axes[i].axis('off')\nplt.subplots_adjust(wspace=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating training and testing data","metadata":{}},{"cell_type":"code","source":"X = np.array([ x[0] for x in data])\ny = np.array([Y[1] for Y in data])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train shape: \", X_train.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"-------------------------------\")\nprint(\"X_test shape: \", X_test.shape)\nprint(\"y_test shape: \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshaping y_train and y_test\ny_train = np.reshape(y_train, (len(y_train),1))\ny_test  = np.reshape(y_test , (len(y_test ),1))\n\nprint(\"After reshaping\")\nprint(\"y_train shape: \", y_train.shape)\nprint(\"y_test shape: \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_Gabor  = X_train\nX_test_Gabor = X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adding color channel ","metadata":{}},{"cell_type":"code","source":"X_train = np.expand_dims(X_train, axis=3)\nX_test = np.expand_dims(X_test, axis=3)\n\nprint(\"After adding color channel\")\nprint(\"X_train shape: \", X_train.shape)\nprint(\"X_test shape: \", X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizing pixel values ","metadata":{}},{"cell_type":"code","source":"X_train = X_train / 255.0\nX_test = X_test / 255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting single values to category array ","metadata":{}},{"cell_type":"code","source":"y_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_SVM = y_train\ny_test_SVM = y_test\n\ny_train = tf.keras.utils.to_categorical(y_train)\ny_test = tf.keras.utils.to_categorical(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"markdown","source":"# [HOG technqiue](https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/) \nFor more info on implementation [visit here](https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/)","metadata":{}},{"cell_type":"code","source":"from skimage.transform import resize\nfrom skimage.feature import hog","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How Hog looks ?","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\n\n\nplt.subplot(1,2,1)\nimg = random.choice(X_train)\n# first image needs to be resized before passing it to HOG descriptor\nresized_img =  resize(img, (128, 64))\nplt.title(\"Original image\")\nplt.imshow(img, cmap='gray')\nfd, hog_image = hog(\n    resized_img, \n    orientations=9, \n    pixels_per_cell=(8, 8),\n    cells_per_block=(2, 2), \n    visualize=True, \n    multichannel=True\n)\nplt.subplot(1,2,2)\nplt.title(\"HOG\")\nplt.imshow(resize(hog_image, (48, 48)), cmap='gray')\nplt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Feature Vectors for training and testing ","metadata":{}},{"cell_type":"code","source":"def Create_Hog_features(data):\n    Feature_data = np.zeros((len(data),48,48))\n\n    for i in range(len(data)):\n        img = data[i]\n        resized_img = resize(img, (128, 64))\n        fd, hog_image = hog(\n            resized_img, \n            orientations=9, \n            pixels_per_cell=(8, 8),\n            cells_per_block=(2, 2), \n            visualize=True, \n            multichannel=True\n        )\n        Feature_data[i] = resize(hog_image, (48, 48))\n    return Feature_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Feature_X_train = Create_Hog_features(X_train)\nFeature_X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(random.choice(Feature_X_train), cmap='gray')\nplt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# doing same for test data \nFeature_X_test = Create_Hog_features(X_test)\n\nFeature_X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(random.choice(Feature_X_test), cmap='gray')\nplt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Again adding color channel as it got removed while converting img to hog img\nX_train_HOG = np.expand_dims(Feature_X_train, axis=3)\nX_test_HOG = np.expand_dims(Feature_X_test, axis=3)\n\nprint(\"After adding color channel\")\nprint(\"X_train_HOG shape: \", X_train_HOG.shape)\nprint(\"X_test_HOG shape: \", X_test_HOG.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train_HOG shape: \", X_train_HOG.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"X_test_HOG shape: \", X_test_HOG.shape)\nprint(\"y_test shape: \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Augmentation","metadata":{}},{"cell_type":"code","source":"# train_datagen = ImageDataGenerator(\n#     rotation_range=25, width_shift_range=0.1,\n#     height_shift_range=0.1, shear_range=0.2, \n#     zoom_range=0.2,horizontal_flip=True, \n#     fill_mode=\"nearest\"\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and testing the HOG - CNN model","metadata":{}},{"cell_type":"markdown","source":"Referred from [here](https://www.kaggle.com/milan400/human-emotion-detection-by-using-cnn#Creating-Model)","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape=None):\n    if input_shape is None :\n        input_shape=(48,48,1)\n\n    model = Sequential()\n    model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(7, activation = 'softmax'))\n    \n    return model ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(\n    monitor='val_accuracy', min_delta=0.0001, patience=10, verbose=2,\n    mode='max', baseline=None, restore_best_weights=True\n)\nlr = ReduceLROnPlateau(\n    monitor='val_accuracy', factor=0.1, patience=5, verbose=2,\n    mode='max', min_delta=1e-5, cooldown=0, min_lr=0\n)\n\ncallbacks = [es, lr]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOG_model = create_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOG_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOG_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOG_history = HOG_model.fit(X_train_HOG, y_train, batch_size=8 , epochs=50, validation_data = (X_test_HOG, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_performance(history):\n    plt.figure(figsize=(12, 8))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(history.history['loss'], label='train')\n    plt.plot(history.history['val_loss'], label='val')\n\n    plt.legend()\n    plt.grid()\n    plt.title('train and val loss evolution')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='val')\n\n    plt.legend()\n    plt.grid()\n    plt.title('train and val accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_performance(HOG_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOG_acc = HOG_model.evaluate(X_test_HOG, y_test, verbose = 0)[1]\nacc.append(HOG_acc)\nprint(\"HOG Accuracy :\",HOG_model.evaluate(X_test_HOG, y_test, verbose = 0)[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOG_model.save('HOG_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LBP technqiue\nImplementation Referred from [here](https://github.com/salonibhatiadutta/To-get-the-local-binary-pattern-LBP-of-image-and-draw-its-histogram/blob/master/gray_image_conversion.ipynb)","metadata":{}},{"cell_type":"code","source":"def Binarypattern(im):                               # creating function to get local binary pattern\n    img= np.zeros_like(im)\n    n=3                                              # taking kernel of size 3*3\n    for i in range(0,im.shape[0]-n):                 # for image height\n        for j in range(0,im.shape[1]-n):               # for image width\n            x  = im[i:i+n,j:j+n]                     # reading the entire image in 3*3 format\n            center       = x[1,1]                    # taking the center value for 3*3 kernel\n            img1        = (x >= center)*1.0          # checking if neighbouring values of center value is greater or less than center value\n            img1_vector = img1.T.flatten()           # getting the image pixel values \n            img1_vector = np.delete(img1_vector,4)  \n            digit = np.where(img1_vector)[0]         \n            if len(digit) >= 1:                     # converting the neighbouring pixels according to center pixel value\n                num = np.sum(2**digit)              # if n> center assign 1 and if n<center assign 0\n            else:                                    # if 1 then multiply by 2^digit and if 0 then making value 0 and aggregating all the values of kernel to get new center value\n                num = 0\n            img[i+1,j+1] = num\n    return(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How LBP looks ?","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\n\nplt.subplot(1,2,1)\nimg = random.choice(X_train)\nplt.title(\"Original  image\")\nplt.imshow(img, cmap='gray')\n\nplt.subplot(1,2,2)\nplt.title(\"LBP\")\nimgLBP=Binarypattern(img)             # calling the LBP function using gray image\nplt.imshow(imgLBP, cmap='gray')\nplt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Feature Vectors for training and testing ","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_LBP_features(data):\n    Feature_data = np.zeros(data.shape)\n\n    for i in range(len(data)):\n        img = data[i]\n        imgLBP=Binarypattern(img)  \n        Feature_data[i] = imgLBP\n    \n    return Feature_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Feature_X_train = create_LBP_features(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Feature_X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = random.choice(Feature_X_train)\nplt.imshow(img, cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Feature_X_test = create_LBP_features(X_test)\nFeature_X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = random.choice(Feature_X_test)\nplt.imshow(img, cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and testing LBP-CNN model","metadata":{}},{"cell_type":"code","source":"LBP_model = create_model()\nLBP_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LBP_history = LBP_model.fit(Feature_X_train, y_train, batch_size=8 , epochs=50, validation_data = (Feature_X_test, y_test) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_performance(LBP_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LBP_acc = LBP_model.evaluate(Feature_X_test, y_test, verbose = 0)[1]\nacc.append(LBP_acc)\nprint(\"LBP Accuracy :\",LBP_model.evaluate(Feature_X_test, y_test, verbose = 0)[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LBP_model.save('LBP_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SIFT ","metadata":{}},{"cell_type":"markdown","source":"### Let's see some SIFT features ","metadata":{}},{"cell_type":"code","source":"L = 3\nW = 3\nfig, axes = plt.subplots(L, W, figsize = (15,15))\naxes = axes.ravel()\n\nfor i in range(0, L * W):  \n    sample = random.choice(data)\n    image8bit = cv2.normalize(sample[0], None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n    sift = cv2.SIFT_create()\n    kp, des = sift.detectAndCompute(image8bit,None)\n\n    img = cv2.drawKeypoints(image=image8bit, outImage=sample[0], keypoints = kp, flags = 4, color = (255, 0, 0))\n    axes[i].set_title(\"Expression = \"+str(CATEGORIES[sample[1]]))\n    axes[i].imshow(img, cmap='gray')\n    axes[i].axis('off')\nplt.subplots_adjust(wspace=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"so to create a feature vector we will have to create an empty array of shape (len(data), 48,48,3) ","metadata":{}},{"cell_type":"markdown","source":"### Creating Feature Vectors for training and testing ","metadata":{}},{"cell_type":"code","source":"def create_SIFT_features(data):\n    Feature_data = np.zeros((len(data),48,48,3))\n\n    for i in range(len(data)):\n        img = data[i]\n        image8bit = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n        sift = cv2.SIFT_create()\n        kp, des = sift.detectAndCompute(image8bit,None)\n\n        img = cv2.drawKeypoints(image=image8bit, outImage=img, keypoints = kp, flags = 4, color = (255, 0, 0))\n        Feature_data[i] = img/255.0\n\n        \n    return Feature_data ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_SIFT = create_SIFT_features(X_train) \nX_train_SIFT.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_train_SIFT[0], cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_SIFT = create_SIFT_features(X_test) \nX_test_SIFT.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_test_SIFT[0], cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIFT_model = create_model(input_shape=(48,48,3))\nSIFT_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIFT_history = SIFT_model.fit(X_train_SIFT, y_train, batch_size=8 , epochs=50, validation_data = (X_test_SIFT, y_test),  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_performance(SIFT_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIFT_acc = SIFT_model.evaluate(X_test_SIFT, y_test, verbose = 0)[1]\nacc.append(SIFT_acc)\nprint(\"SIFT Accuracy :\",SIFT_model.evaluate(X_test_SIFT, y_test, verbose = 0)[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIFT_model.save('SIFT_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gabor Filters \nwith help of my friend : https://www.kaggle.com/sashankmvv/gabor-cnn-ck/notebook","metadata":{}},{"cell_type":"code","source":"def Gabor_filter(K_size=111, Sigma=10, Gamma=1.2, Lambda=10, Psi=0, angle=0):\n    # get half size\n    d = K_size // 2\n\n    # prepare kernel\n    gabor = np.zeros((K_size, K_size), dtype=np.float32)\n\n    # each value\n    for y in range(K_size):\n        for x in range(K_size):\n            # distance from center\n            px = x - d\n            py = y - d\n\n            # degree -> radian\n            theta = angle / 180. * np.pi\n\n            # get kernel x\n            _x = np.cos(theta) * px + np.sin(theta) * py\n\n            # get kernel y\n            _y = -np.sin(theta) * px + np.cos(theta) * py\n\n            # fill kernel\n            gabor[y, x] = np.exp(-(_x**2 + Gamma**2 * _y**2) / (2 * Sigma**2)) * np.cos(2*np.pi*_x/Lambda + Psi)\n\n    # kernel normalization\n    gabor /= np.sum(np.abs(gabor))\n\n    return gabor\n\n\n# Use Gabor filter to act on the image\ndef Gabor_filtering(gray, K_size=111, Sigma=10, Gamma=1.2, Lambda=10, Psi=0, angle=0):\n    # get shape\n    H, W = gray.shape\n\n    # padding\n    gray = np.pad(gray, (K_size//2, K_size//2), 'edge')\n\n    # prepare out image\n    out = np.zeros((H, W), dtype=np.float32)\n\n    # get gabor filter\n    gabor = Gabor_filter(K_size=K_size, Sigma=Sigma, Gamma=Gamma, Lambda=Lambda, Psi=0, angle=angle)\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            out[y, x] = np.sum(gray[y : y + K_size, x : x + K_size] * gabor)\n\n    out = np.clip(out, 0, 255)\n    out = out.astype(np.uint8)\n\n    return out\n\n\n# Use 6 Gabor filters with different angles to perform feature extraction on the image\ndef Gabor_process(img):\n#     print(img.shape)\n    # get shape\n    H, W = img.shape\n\n    # gray scale\n#     gray = BGR2GRAY(img).astype(np.float32)\n\n    # define angle\n    #As = [0, 45, 90, 135]\n    As = [0,30,60,90,120,150]\n\n    # prepare pyplot\n#     plt.subplots_adjust(left=0, right=1, top=1, bottom=0, hspace=0, wspace=0.2)\n\n    out = np.zeros([H, W], dtype=np.float32)\n\n    # each angle\n    for i, A in enumerate(As):\n    \n        # gabor filtering\n        _out = Gabor_filtering(img, K_size=11, Sigma=1.5, Gamma=1.2, Lambda=3, angle=A)\n         \n\n        # add gabor filtered image\n        out += _out\n        \n\n    # scale normalization\n    out = out /out.max()*255\n    out = out.astype(np.uint8)\n\n    return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_Gabor_features(data):\n    Feature_data = np.zeros((len(data),48,48,1))\n\n    for i in range(len(data)):\n        img = data[i]\n        out = Gabor_process(img)\n        out = np.expand_dims(out , axis = 2) # adding color channel\n        Feature_data[i] = out/255.00\n\n        \n    return Feature_data ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_train_Gabor[0]/255.0, cmap ='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_Gabor=create_Gabor_features(X_train_Gabor)\nX_test_Gabor=create_Gabor_features(X_test_Gabor)\n\nX_train_Gabor.shape , X_test_Gabor.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = random.randint(100,500)\nplt.subplot(1,2,1)\nplt.imshow(X_train[sample],cmap='gray')\nplt.axis(\"off\")\nplt.subplot(1,2,2)\nplt.imshow(X_train_Gabor[sample],cmap='gray')\nplt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_Gabor.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Gabor_model = create_model()\nGabor_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Gabor_history = Gabor_model.fit(X_train_Gabor, y_train, batch_size=8 , epochs=50, validation_data = (X_test_Gabor, y_test) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_performance(Gabor_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n# plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Gabor_acc = Gabor_model.evaluate(X_test_Gabor, y_test, verbose = 0)[1]\nacc.append(Gabor_acc)\nprint(\"Gabor Accuracy :\",Gabor_model.evaluate(X_test_Gabor, y_test, verbose = 0)[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Gabor_model.save('Gabor_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Without Feature Extraction ","metadata":{}},{"cell_type":"code","source":"WFE_model = create_model()\nWFE_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WFE_history = WFE_model.fit(X_train, y_train, batch_size=8 , epochs=50, validation_data = (X_test, y_test) ,callbacks = [callbacks])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_performance(WFE_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WFE_acc = WFE_model.evaluate(X_test, y_test, verbose = 0)[1]\nacc.append(WFE_acc)\nprint(\"Without Feature extraction Accuracy :\", WFE_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WFE_model.save('WFE_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing accuracies ","metadata":{}},{"cell_type":"code","source":"acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(acc, index=['HOG', 'LBP', 'SIFT', 'Gabor', 'Without Feature Extraction'], columns = ['Accuracies'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def emotion_analysis(emotions):\n    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n    y_pos = np.arange(len(objects))\n    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=HOG_model.predict(X_test)\n#print(y_pred)\ny_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import io\nimg = image.load_img('/kaggle/input/testimg/download.jpeg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('/kaggle/input/testimg/download.jpeg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = HOG_model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}